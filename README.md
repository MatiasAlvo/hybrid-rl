# Hybrid Policy Optimization in Discontinuous MDPs: Combining Pathwise and Model-Free Gradient Estimators

Implementation of hybrid methods combining differentiable simulation with model-free reinforcement learning (e.g., PPO) for solving Markov Decision Processes (MDPs) with discontinuities.

## Introduction

Many real-world sequential decision problems involve **discontinuities** in cost functions or transitions (e.g., fixed costs, minimum order quantities, or bulk discounts). Standard **pathwise gradient** methods fail in these settings, while purely **model-free** methods suffer from high variance.

This project implements **hybrid approaches** that combine low-variance pathwise gradients with score-function ones. Our main contribution is to develop a hybrid algorithm that combines PPO with HDPO (which uses pathwise gradients.)

We explore several agent architectures including:
- **HybridAgent**: Agent that combines PPO with HDPO (pathwise gradients)
- **GumbelSoftmaxAgent**: Uses the straight-through trick and adds Gumbel noise, allowing to use pathwise gradients only  
- **FactoredGaussianPPOAgent**: Pure PPO approach with Gaussian continuous actions 


## Installation

To set up the environment for this project, follow these steps:

1. Clone this repository to your local machine:

```
git clone git@github.com:MatiasAlvo/hybrid-rl.git
```

2. Navigate to the project directory:
```
cd hybrid-rl
```

3. Create a conda environment using the provided environment.yml file
```
conda env create -f environment.yml
```

4. Activate the conda environment:
```
conda activate exp_neural
```

**Note**: The environment.yml includes PyTorch with CUDA 11.8 support. If you need CUDA 12.1 or CPU-only PyTorch, modify the `pytorch-cuda=11.8` line in environment.yml before creating the environment.

## Project Structure

- `src/algorithms/hybrid/agents/hybrid_agent.py`: Implementation of various agent architectures, including our proposed Hybrid agent, the FactoredGaussianPPO and GumbelSoftmax agents
- `src/algorithms/hybrid/optimizer_wrapper/hybrid_wrapper.py`: Optimizer wrapper that allows to train using PPO and HDPO loss components for hybrid training
- `src/features/feature_registry.py`: Feature processing and normalization system for handling hybrid action spaces
- `src/training/trainer.py`: Main training loop orchestrating agent training with logging and model checkpointing
- `src/envs/inventory/hybrid_simulator.py`: Implementation of the hybrid simulator supporting discontinuous cost functions and transitions
- `src/algorithms/common/policies/`: Policy network architectures for different agent types
- `src/environments/`: MDP environments with discontinuities
- `config_files/`: Experiment configurations

The code can be executed from the terminal by running the following:
```
python3 main_run.py [mode] [config_file_path] [hyperparameters_file_path]
```
Here, `[mode]` can be either `train` or `test`. If `train` is specified, the model is executed on the test set after training. The last two parameters define the filenames for the configuration files for the environment and hyperparameters, respectively. For example, if you want to train (and then test) a model for the setting defined in `fixed_costs`, considering the hyperparameters (including neural network architecture) defined in the file `hybrid`, you should run:
```
python3 main_run.py train fixed_costs hybrid
```

We allow for providing the filenames for the setting and hyperparameter config files in `main_run.py`, in which case the last 2 parameters have to be omitted in the terminal. For example, you can run:
```
python3 main_run.py train
```
and specify the filenames within the main script.


## Populating a config file

### Setting config file

#### `seeds` and `test_seeds`:
- `underage_cost`: Seed to sample underage costs, in case they are random.
- `holding_cost`: Seed to sample holding costs, in case they are random.
- `mean`: Seed to sample mean parameters, in case they are random.
- `coef_of_var`: Seed to sample the coefficient of variations (which defines the standard deviation), in case they are random.
- `lead_time`: Seed to sample lead times, in case they are random.
- `demand`: Seed to sample demand traces.
- `initial_inventory`: Seed to sample the value of initial inventories at the stores.

#### `sample_data_params`:
- `split_by_period`: Whether to split the dataset by period or by sample. If True (currently only used for setting with real data), train, dev and test sets
are generated by copying all values (costs and lead times), and splitting demand traces into disjoint sets of periods.

#### `problem_params`: 
- `n_stores`: The number of stores in the inventory network.
- `n_warehouses`: The number of warehouses in the inventory network.
- `n_extra_echelons`: The number of extra echelons in the inventory network.
- `lost_demand`: Whether to consider unmet demand to be lost or backlogged.
- `maximize_profit`: True if objective is to maximize profit. False if objective is to minimize cost.

#### `params_by_dataset`: one dictionary for each of train, dev and test, containing
- `n_samples`: The number of samples in the dataset.
- `batch_size`: The batch size for training.
- `periods`: The number of periods to simulate.
- `ignore_periods`: The number of initial periods to ignore for purposes of reporting costs.

#### `observation_params`: defines which information is containted in the observation
- `include_warehouse_inventory`: Whether to include warehouse inventory in observations.
- `include_static_features`: 
  - `holding_costs`: Whether to include holding costs in observations.
  - `underage_costs`: Whether to include underage costs in observations.
  - `lead_times`: Whether to include lead times in observations.
- `demand`: 
  - `past_periods`: The number of past periods to include in demand observations.
  - `period_shift`: The shift in demand periods. It shifts the beginning of the planning horizon from 0 to this value.
- `include_past_observations`:
  - `arrivals`: The number of past arrivals to include in observations.
  - `orders`: The number of past orders to include in observations.
- `time_features_file`: Path to the file containing time-related features.
- `time_features`: List of time-related features to include (e.g., 'days_from_christmas').
- `sample_features_file`: Path to the file containing scenario-related features (e.g., product type).
- `sample_features`: List of scenario-related features to include (e.g., 'store_nbr').

#### `store_params`:
- `demand`: 
  - `sample_across_stores`: Whether to sample the parameters for each store. Only works for normal distributions. If True, sample in the ranges specified in `mean_range` and `coef_of_var_range`.
  - `vary_across_samples`: Whether to sample the parameters for each different scenario. Only works for normal distributions. If True, sample in the ranges specified in `mean_range` and `coef_of_var_range`.
  - `expand`: Whether the copy demand parameters across all stores and scenarios by "expanding". If True, we copy the values of `mean` and `std`.
  - `mean_range`: The range from which to sample the mean of demands.
  - `coef_of_var_range`: The range of the coefficient of variation of the demand distribution from which to sample.
  - `mean`: Mean of the distribution, which is fixed across all stores and samples.
  - `std`: Standard deviation of the distribution, which is fixed across all stores and samples.
  - `distribution`: The distribution of demand. Can be normal, poisson or real.
  - `correlation`: The correlation coefficient for pairwise demands.
  - `clip`: Whether to clip demand values below from 0.
  - `decimals`: The number of decimals for demand values.
- `lead_time/holding_cost/underage_cost`: 
  - `sample_across_stores`: Whether to sample the parameters for each store.
  - `vary_across_samples`: Whether to sample the parameters for each different scenario. If True, sample in the range specified in `range`.
  - `expand`: Whether the copy demand parameters across all stores and scenarios by "expanding". If True, we copy the value `value`.
  - `range`: The range from which to sample the parameter values.
  - `value`: Value to be copied across all stores and scenarios
  - `file_location`: Location for directly reading the values of the parameters, instead of defining them manually.
- `initial_inventory`: 
  - `sample`: True if considering a random initial inventory, given as random_value*mean_demand_per_store.
  - `range_mult`: The range from which to sample random_value.
  - `inventory_periods`: How many periods to consider for the inventories state (which might be larger that lead time, if specified).

#### `warehouse_params`:
- `holding_cost`: The holding cost for the warehouse.
- `lead_time`: The lead time for the warehouse.

#### `echelon_params`:
  - `holding_cost`: A list specifying the holding cost for each echelon.
  - `lead_time`: A list specifying the lead time for each echelon.

### Config file for Hyperparameters and Neural Network Architectures

#### `trainer_params`:
- `epochs`: The number of epochs to train the neural network.
- `do_dev_every_n_epochs`: Perform evaluation on the dev dataset every `n` epochs.
- `print_results_every_n_epochs`: Print training results every `n` epochs.
- `save_model`: Whether to save the trained model.
- `epochs_between_save`: Number of epochs between model saving (and only if performance improved).
- `choose_best_model_on`: Performance on which to select the best model. Can be `dev_loss` or `train_loss`
- `load_previous_model`: Whether to load a previously trained model.
- `load_model_path`: Path to the previously trained model.

#### `optimizer_params`:
- `learning_rate`: The learning rate used by the optimizer.

#### `nn_params`:
- `name`: The name of the neural network architecture.
- `inner_layer_activations`: Activation functions for inner layers of each component/module of the neural network.
- `output_layer_activation`: Activation function for the output layer of each component/module of the neural network.
- `neurons_per_hidden_layer`: Number of neurons for each hidden layer of each component/module of the neural network.
- `output_sizes`: Size of the output layer for each component of the neural network.
- `initial_bias`: Initial bias for the last layer of each component/module of the neural network.
- `forecaster_location`: Location for loading quantile forecaster, if used within the policy.
- `warehouse_upper_bound_mult`: Multiplier to calculate the upper bound for warehouse outputs.

## License

MIT License

Copyright 2025 Matias Alvo

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.