trainer_params:
  'epochs': 250
  'do_dev_every_n_epochs': 1
  'print_results_every_n_epochs': 1
  'save_model': false
  'epochs_between_save': 1
  'choose_best_model_on': 'dev_loss'
  'load_previous_model': false
  'load_model_path': ''
  'base_dir': 'models/saved_models'
  'compute_metrics_on_test': false

logging_params: 
  'use_wandb': false
  'use_tensorboard': false
  'wandb_project_name': "inventory_control"
  'wandb_entity': "alvomatias"
  'exp_name': "hybrid"
  'env_name': "inventory"
  'setting_name': "one_store_fixed_costs"
  'log_inventory_action_plot': false
  'log_inventory_value_plot': false
  'log_inventory_discrete_action0_prob_plot': false

agent_params:
  'agent_type': 'hybrid'
  'initial_temperature': 1.0
  'min_temperature': 0.001
  'temperature_decay': 0.997
  'use_straight_through': false
  'add_gumbel_noise': false

optimizer_params:
  # 'learning_rate': 0.03
  'learning_rate': 0.0001
  'anneal_lr': false
  'weight_decay': 0.0
  'lr_multipliers':
    'value': 1.0
    'backbone': 1.0
    'continuous': 1.0
    'discrete': 1.0
    'other': 1.0
  'ppo_params':
    'clip_coef': 0.16
    'gamma': 0.93
    'gae_lambda': 0.96
    'normalize_advantages': true
    'use_gae': true
    'num_epochs': 5
    'value_function_coef': 0.13
    'pathwise_coef': 10.0
    'reward_scaling_pathwise': true
    'reward_scaling': true
    'buffer_periods': 20
    'max_grad_norm': 5.0
    'entropy_coef': 0.0
    'clip_by_component': true

nn_params:
  policy_network:
    name: 'hybrid_policy'
    # name: 'separate_network_policy'
    input_size: null
    hidden_layers: [64, 64]
    activation: 'ELU'
    # activation: 'Tanh'
    dropout: 0.0
    batch_norm: false
    continuous_scale: 1.0
    # continuous_shift: 0.0 # for sigmoid this needs to be 0 or a low value
    continuous_shift: 5.0
    # continuous_scale: 100.0
    observation_keys: ['store_inventories', 'holding_costs', 'underage_costs', 'lead_times', 'procurement_costs', 'past_demands', 'days_from_christmas']
    normalize_by_mean_demand: true  # Normalize quantity-related inputs by mean demand
    # scale_by_mean_demand: false  # NEW PARAMETER
    heads:
      discrete:
        enabled: true
        size: 0 # override in range manager
        activation: 'Linear'
      continuous:
        enabled: true
        size: 0 # override in range manager
        activation: 'Linear'

  value_network:
    enabled: true
    input_size: 2
    hidden_layers: [64, 64]
    activation: 'Tanh'
    # activation: 'ELU'
    dropout: 0.0
    batch_norm: false
    output_size: 1 