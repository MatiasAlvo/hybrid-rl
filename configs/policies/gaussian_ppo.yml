trainer_params:
  'epochs': 150
  'do_dev_every_n_epochs': 1
  'print_results_every_n_epochs': 1
  'save_model': false
  'epochs_between_save': 1
  'choose_best_model_on': 'dev_loss'
  'load_previous_model': false
  'load_model_path': ''
  'base_dir': 'models/saved_models'
  'compute_metrics_on_test': true

logging_params: 
  'use_wandb': true
  'use_tensorboard': false
  'wandb_project_name': "inventory_control"
  'wandb_entity': "alvomatias"
  'exp_name': "gaussian_ppo"
  'env_name': "inventory"
  'setting_name': "one_store_fixed_costs"

agent_params:
  'agent_type': 'gaussian_ppo'

optimizer_params:
  'learning_rate': 0.00015
  'anneal_lr': true
  'weight_decay': 0.0
  'gradient_clip': 1.0
  'ppo_params':
    'clip_coef': 0.2
    'gamma': 0.95
    'gae_lambda': 0.95
    'normalize_advantages': true
    'use_gae': true
    'num_epochs': 5
    'value_function_coef': 0.1

nn_params:
  policy_network:
    name: 'gaussian_ppo_policy'
    input_size: 2
    hidden_layers: [64, 64]
    activation: 'Tanh'
    dropout: 0.0
    batch_norm: false
    heads:
      continuous:
        enabled: true
        size: 0 # override in range manager
        activation: 'Linear'

  value_network:
    enabled: true
    input_size: 2
    hidden_layers: [64, 64]
    activation: 'Tanh'
    dropout: 0.0
    batch_norm: false
    output_size: 1
