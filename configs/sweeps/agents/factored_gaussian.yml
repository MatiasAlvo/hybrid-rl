# Factored Gaussian PPO Agent Sweep Configuration
config_files:
  hyperparams: 'configs/policies/factored_gaussian_ppo.yml'

method: 'random'
metric:
  name: 'dev/loss/best'
  goal: 'minimize'

parameters:
  anneal_lr:
    values:
      - true
      - false
  buffer_periods:
    values:
      - 10
      - 30
  clip_coef:
    distribution: uniform
    max: 0.2
    min: 0.1
  gae_lambda:
    distribution: uniform
    max: 0.97
    min: 0.95
  gamma:
    distribution: uniform
    max: 0.95
    min: 0.92
  learning_rate:
    distribution: log_uniform_values
    max: 0.01
    min: 0.0001
  max_grad_norm:
    distribution: uniform
    max: 10
    min: 1
  normalize_advantages:
    values:
      - true
  normalize_observations:
    values:
      - false
  num_epochs:
    values:
      - 5
      - 3
  pathwise_coef:
    distribution: uniform
    max: 10
    min: 0.1
  policy_activation:
    values:
      - Tanh
      - ELU
  reward_scaling:
    values:
      - true
  use_gae:
    values:
      - true
  value_activation:
    values:
      - Tanh
  value_function_coef:
    distribution: log_uniform_values
    max: 0.2
    min: 0.1
  use_wandb:
    values:
      - true
  continuous_shift:
    values:
      - 1.0
      - 5.0
  normalize_by_mean_demand:
    values:
      - true
      - false